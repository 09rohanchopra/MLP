{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Four tasks\n",
    "\n",
    "* ### Implement forward and backward for FCLayer (`layers/fc_layer.py`)\n",
    "* ### Implement forward and backward for ReLULayer (`layers/relu_layer.py`)\n",
    "* ### Implement forward and backward for SigmoidLayer (`layers/sigmoid_layer.py`)\n",
    "* ### Implement sgd with momentum (`optimizer.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from network import Network\n",
    "\n",
    "from builtin import BuiltInFCLayer, BuiltInReLULayer, BuiltInSigmoidLayer, BuiltInSGDwithMomentum\n",
    "\n",
    "from layers import FCLayer, ReLULayer, SigmoidLayer\n",
    "\n",
    "from criterion import SoftmaxCrossEntropy\n",
    "from optimizer import SGD, SGDwithMomentum\n",
    "\n",
    "from solver import train, test\n",
    "from plot import plot_loss_and_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "max_epoch = 20\n",
    "init_std = 0.01\n",
    "\n",
    "learning_rate = 0.1\n",
    "weight_decay = 0.00005\n",
    "momentum = 0.9\n",
    "\n",
    "disp_freq = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", validation_size=5000, one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterion and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = SoftmaxCrossEntropy()\n",
    "sgd = SGD(learning_rate, weight_decay)\n",
    "sgd_momentum = BuiltInSGDwithMomentum(learning_rate, weight_decay, momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP with sigmoid activation function \n",
    "\n",
    "Build and train a MLP with one hidden layer with 256 units using sigmoid activation function and crossentropy loss\n",
    "\n",
    "## Before executing the following code, you should implement FCLayer and SigmoidLayer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model (see Framework_demo.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SigmoidMLP = Network()\n",
    "# TODO build SigmoidMLP with FCLayer and SigmoidLayer\n",
    "SigmoidMLP.add(FCLayer(784, 256, init_std))\n",
    "SigmoidMLP.add(SigmoidLayer())\n",
    "SigmoidMLP.add(FCLayer(256, 10, init_std))\n",
    "\n",
    "\n",
    "# Criterion\n",
    "criterion = SoftmaxCrossEntropy()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = SGD(learning_rate, weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][20]\t Batch [0][550]\t Training Loss 2.2998\t Accuracy 0.0400\n",
      "Epoch [0][20]\t Batch [50][550]\t Training Loss 2.3024\t Accuracy 0.1131\n",
      "Epoch [0][20]\t Batch [100][550]\t Training Loss 2.3025\t Accuracy 0.1090\n",
      "Epoch [0][20]\t Batch [150][550]\t Training Loss 2.3024\t Accuracy 0.1107\n",
      "Epoch [0][20]\t Batch [200][550]\t Training Loss 2.3021\t Accuracy 0.1120\n",
      "Epoch [0][20]\t Batch [250][550]\t Training Loss 2.3021\t Accuracy 0.1116\n",
      "Epoch [0][20]\t Batch [300][550]\t Training Loss 2.3019\t Accuracy 0.1125\n",
      "Epoch [0][20]\t Batch [350][550]\t Training Loss 2.3017\t Accuracy 0.1121\n",
      "Epoch [0][20]\t Batch [400][550]\t Training Loss 2.3017\t Accuracy 0.1116\n",
      "Epoch [0][20]\t Batch [450][550]\t Training Loss 2.3016\t Accuracy 0.1123\n",
      "Epoch [0][20]\t Batch [500][550]\t Training Loss 2.3016\t Accuracy 0.1126\n",
      "Epoch [0]\t Average training loss 2.3016\t Average training accuracy 0.1121\n",
      "Epoch [0]\t Average validation loss 2.3010\t Average validation accuracy 0.1126\n",
      "\n",
      "Epoch [1][20]\t Batch [0][550]\t Training Loss 2.2925\t Accuracy 0.1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "layers/sigmoid_layer.py:18: RuntimeWarning: overflow encountered in exp\n",
      "  Output = 1 / (1 + np.exp(-Input))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1][20]\t Batch [50][550]\t Training Loss 2.3004\t Accuracy 0.1208\n",
      "Epoch [1][20]\t Batch [100][550]\t Training Loss 2.3018\t Accuracy 0.1138\n",
      "Epoch [1][20]\t Batch [150][550]\t Training Loss 2.3015\t Accuracy 0.1140\n",
      "Epoch [1][20]\t Batch [200][550]\t Training Loss 2.3011\t Accuracy 0.1160\n",
      "Epoch [1][20]\t Batch [250][550]\t Training Loss 2.3012\t Accuracy 0.1156\n",
      "Epoch [1][20]\t Batch [300][550]\t Training Loss 2.3013\t Accuracy 0.1141\n",
      "Epoch [1][20]\t Batch [350][550]\t Training Loss 2.3015\t Accuracy 0.1130\n",
      "Epoch [1][20]\t Batch [400][550]\t Training Loss 2.3014\t Accuracy 0.1129\n",
      "Epoch [1][20]\t Batch [450][550]\t Training Loss 2.3014\t Accuracy 0.1129\n",
      "Epoch [1][20]\t Batch [500][550]\t Training Loss 2.3015\t Accuracy 0.1127\n",
      "Epoch [1]\t Average training loss 2.3015\t Average training accuracy 0.1123\n",
      "Epoch [1]\t Average validation loss 2.3013\t Average validation accuracy 0.1126\n",
      "\n",
      "Epoch [2][20]\t Batch [0][550]\t Training Loss 2.3108\t Accuracy 0.1000\n",
      "Epoch [2][20]\t Batch [50][550]\t Training Loss 2.3019\t Accuracy 0.1133\n",
      "Epoch [2][20]\t Batch [100][550]\t Training Loss 2.3018\t Accuracy 0.1137\n",
      "Epoch [2][20]\t Batch [150][550]\t Training Loss 2.3017\t Accuracy 0.1146\n",
      "Epoch [2][20]\t Batch [200][550]\t Training Loss 2.3017\t Accuracy 0.1134\n",
      "Epoch [2][20]\t Batch [250][550]\t Training Loss 2.3018\t Accuracy 0.1126\n",
      "Epoch [2][20]\t Batch [300][550]\t Training Loss 2.3017\t Accuracy 0.1132\n",
      "Epoch [2][20]\t Batch [350][550]\t Training Loss 2.3016\t Accuracy 0.1129\n",
      "Epoch [2][20]\t Batch [400][550]\t Training Loss 2.3016\t Accuracy 0.1124\n",
      "Epoch [2][20]\t Batch [450][550]\t Training Loss 2.3014\t Accuracy 0.1125\n",
      "Epoch [2][20]\t Batch [500][550]\t Training Loss 2.3015\t Accuracy 0.1126\n",
      "Epoch [2]\t Average training loss 2.3015\t Average training accuracy 0.1123\n",
      "Epoch [2]\t Average validation loss 2.3011\t Average validation accuracy 0.1126\n",
      "\n",
      "Epoch [3][20]\t Batch [0][550]\t Training Loss 2.2961\t Accuracy 0.1400\n",
      "Epoch [3][20]\t Batch [50][550]\t Training Loss 2.3016\t Accuracy 0.1125\n",
      "Epoch [3][20]\t Batch [100][550]\t Training Loss 2.3016\t Accuracy 0.1108\n",
      "Epoch [3][20]\t Batch [150][550]\t Training Loss 2.3018\t Accuracy 0.1112\n",
      "Epoch [3][20]\t Batch [200][550]\t Training Loss 2.3014\t Accuracy 0.1139\n",
      "Epoch [3][20]\t Batch [250][550]\t Training Loss 2.3012\t Accuracy 0.1144\n",
      "Epoch [3][20]\t Batch [300][550]\t Training Loss 2.3014\t Accuracy 0.1139\n",
      "Epoch [3][20]\t Batch [350][550]\t Training Loss 2.3013\t Accuracy 0.1140\n",
      "Epoch [3][20]\t Batch [400][550]\t Training Loss 2.3014\t Accuracy 0.1132\n",
      "Epoch [3][20]\t Batch [450][550]\t Training Loss 2.3014\t Accuracy 0.1128\n",
      "Epoch [3][20]\t Batch [500][550]\t Training Loss 2.3015\t Accuracy 0.1126\n",
      "Epoch [3]\t Average training loss 2.3015\t Average training accuracy 0.1123\n",
      "Epoch [3]\t Average validation loss 2.3013\t Average validation accuracy 0.1126\n",
      "\n",
      "Epoch [4][20]\t Batch [0][550]\t Training Loss 2.3038\t Accuracy 0.0700\n",
      "Epoch [4][20]\t Batch [50][550]\t Training Loss 2.3014\t Accuracy 0.1131\n",
      "Epoch [4][20]\t Batch [100][550]\t Training Loss 2.3012\t Accuracy 0.1153\n",
      "Epoch [4][20]\t Batch [150][550]\t Training Loss 2.3014\t Accuracy 0.1136\n",
      "Epoch [4][20]\t Batch [200][550]\t Training Loss 2.3015\t Accuracy 0.1125\n",
      "Epoch [4][20]\t Batch [250][550]\t Training Loss 2.3016\t Accuracy 0.1112\n",
      "Epoch [4][20]\t Batch [300][550]\t Training Loss 2.3015\t Accuracy 0.1124\n",
      "Epoch [4][20]\t Batch [350][550]\t Training Loss 2.3016\t Accuracy 0.1120\n"
     ]
    }
   ],
   "source": [
    "SigmoidMLP, sigmoid_loss, sigmoid_acc = train(SigmoidMLP, criterion, sgd, mnist, max_epoch, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(SigmoidMLP, criterion, mnist, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP with ReLU activation function \n",
    "\n",
    "Build and train a MLP with one hidden layer with 256 units using ReLU activation function and crossentropy loss\n",
    "\n",
    "## Before executing the following code, you should implement **ReLULayer**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ReLUMLP = Network()\n",
    "# TODO build SigmoidMLP with FCLayer and ReLULayer\n",
    "ReLUMLP.add(FCLayer(784, 256, init_std))\n",
    "ReLUMLP.add(ReLULayer())\n",
    "ReLUMLP.add(FCLayer(256, 10, init_std))\n",
    "\n",
    "\n",
    "# Criterion\n",
    "criterion = SoftmaxCrossEntropy()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = SGD(learning_rate, weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ReLUMLP, ReLU_loss, ReLU_acc = train(ReLUMLP, criterion, sgd, mnist, max_epoch, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(ReLUMLP, criterion, mnist, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_loss_and_acc({'Sigmoid': [sigmoid_loss, sigmoid_acc], 'ReLU': [ReLU_loss, ReLU_acc]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sgd with momentum\n",
    "\n",
    "## Before executing the following code, you should implement SGDwithMomentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ReLUMLP_momentum = Network()\n",
    "\n",
    "# TODO build ReLUMLP with FCLayer and ReLULayer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ReLUMLP_momentum, momentum_loss, momentum_acc = train(ReLUMLP_momentum, criterion, sgd_momentum, mnist, max_epoch, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test(ReLUMLP_momentum, criterion, mnist, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_and_acc({'Sigmoid': [sigmoid_loss, sigmoid_acc],\n",
    "                   'ReLU': [ReLU_loss, ReLU_acc], \n",
    "                   'ReLU_Momentum': [momentum_loss, momentum_acc]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
